{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to discharge_medications_with_rxnorm_codes_wholeblock_draft2.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Please execute this code first. The output of this step will serve as a input for the subsequent codes presented below.\n",
    "#medications / rxnorm downloaded list\n",
    "import pandas as pd\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Load RxNorm data\n",
    "rxnorm_data_path = 'rxnorm_medications_without_TTY_filter.csv'\n",
    "rxnorm_data = pd.read_csv(rxnorm_data_path)\n",
    "\n",
    "# Lowercase the RxNorm medication names and convert to a set for fast lookup\n",
    "rxnorm_set = set(rxnorm_data['Medication Name'].str.lower())\n",
    "\n",
    "# Function to extract phrases of up to five words\n",
    "def extract_phrases(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    phrases = set()  # Use set to avoid duplicate phrases\n",
    "    for i in range(len(words)):\n",
    "        for length in range(1, 6):  # Generate phrases of length 1 to 5\n",
    "            if i + length <= len(words):\n",
    "                phrases.add(' '.join(words[i:i+length]))\n",
    "    return phrases\n",
    "\n",
    "# Function to process each row and find matching phrases\n",
    "def process_row(row):\n",
    "    if pd.isna(row['discharge_medications']):\n",
    "        return []\n",
    "    medication_block = row['discharge_medications'].strip().lower()\n",
    "    phrases = extract_phrases(medication_block)\n",
    "    matched_phrases = []\n",
    "    for phrase in phrases:\n",
    "        if phrase in rxnorm_set:\n",
    "            rxnorm_code = rxnorm_data.loc[rxnorm_data['Medication Name'].str.lower() == phrase, 'RxNorm ID'].values[0]\n",
    "            matched_phrases.append((row['subject_id'], row['diagnosis'], phrase, rxnorm_code, row['intent']))\n",
    "        else:\n",
    "            matched_phrases.append((row['subject_id'], row['diagnosis'], phrase, '', row['intent']))\n",
    "    return matched_phrases\n",
    "\n",
    "# Function to apply processing to a chunk of data\n",
    "def process_chunk(chunk):\n",
    "    return chunk.apply(process_row, axis=1).tolist()\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'Structured_format_output_file.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into chunks for parallel processing\n",
    "num_chunks = cpu_count()\n",
    "chunk_size = len(data) // num_chunks + 1\n",
    "chunks = [data.iloc[i*chunk_size:(i+1)*chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "# Use multiprocessing to process chunks in parallel\n",
    "with Pool(num_chunks) as pool:\n",
    "    results = pool.map(process_chunk, chunks)\n",
    "\n",
    "# Flatten the list of results\n",
    "processed_data = [item for sublist in results for subsublist in sublist for item in subsublist]\n",
    "\n",
    "# Create DataFrame from the processed data\n",
    "processed_df = pd.DataFrame(processed_data, columns=['subject_id', 'diagnosis', 'medication_name', 'rxnorm_code', 'intent'])\n",
    "\n",
    "# Save the new dataframe to a CSV file\n",
    "output_file_path = 'discharge_medications_with_rxnorm_codes_part1.csv'\n",
    "processed_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"File saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 132.84it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 180.74it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 177.16it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.85it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 178.82it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.79it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 144.29it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 179.91it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 180.93it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.03it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 176.11it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 170.32it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 180.82it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 179.96it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 174.57it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 171.21it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 180.38it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 158.37it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.72it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 177.88it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 92.65it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 143.60it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 146.52it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 164.63it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 167.22it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.41it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 88.92it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.56it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.65it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.03it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.33it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 160.96it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.16it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 158.64it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.02it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 168.94it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.91it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 161.95it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 163.06it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 164.49it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 144.26it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 129.22it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 141.41it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 138.20it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 158.92it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 160.76it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.61it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 162.74it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 161.83it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 159.16it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.55it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 159.68it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.26it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.83it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 163.50it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 103.49it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 70.80it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 68.00it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 66.61it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 69.68it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 62.52it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 121.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 86.42it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 106.31it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 75.56it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.15it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 135.98it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 160.50it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 150.57it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.35it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 90.46it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 86.98it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 74.73it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 72.70it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 76.17it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:08<00:00, 60.37it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 163.14it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 156.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 127.87it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:10<00:00, 48.79it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 70.38it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:08<00:00, 56.68it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:13<00:00, 36.02it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 132.45it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 72.60it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:20<00:00, 23.97it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:11<00:00, 41.90it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 151.55it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 156.80it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 124.56it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 147.43it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 123.20it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 149.44it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 134.32it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 121.44it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 122.76it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 146.12it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 146.56it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 142.04it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.20it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 149.89it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 133.18it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 126.82it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 136.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 144.44it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 126.66it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 148.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 150.28it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 151.77it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 130.49it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 136.83it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 159.20it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 111.13it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:09<00:00, 53.93it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 98.63it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:11<00:00, 41.97it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 75.54it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 149.74it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 163.87it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.26it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:05<00:00, 86.61it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 125.47it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 165.38it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 179.65it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.58it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.02it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.04it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 175.21it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 174.09it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 176.40it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 176.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 173.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 173.91it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 176.50it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 167.68it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 185.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 168.21it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 178.30it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 174.37it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.85it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 170.94it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 129.34it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 105.97it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 138.68it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.63it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.50it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 165.94it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 171.51it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 171.10it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 171.17it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 177.81it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.40it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 163.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.39it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 149.73it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 140.50it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 173.33it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 172.08it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 158.04it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 158.13it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 104.36it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 104.72it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 142.15it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 133.05it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 120.90it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 122.03it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 151.22it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 145.91it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.25it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 141.35it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.53it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 104.94it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 131.92it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 131.97it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 138.54it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 142.96it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 114.54it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:06<00:00, 82.04it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:07<00:00, 67.37it/s] \n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:04<00:00, 123.86it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 170.05it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.62it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 152.83it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.74it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 169.57it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 162.03it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 173.00it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 136.71it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 160.74it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 172.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 164.65it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 171.16it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 173.60it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 167.60it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 170.19it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:02<00:00, 167.31it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 155.81it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 161.79it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 126.97it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 500/500 [00:03<00:00, 157.39it/s]\n",
      "Fetching RxNorm codes: 100%|██████████| 438/438 [00:02<00:00, 153.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved to discharge_meds_output_with_rxnorm_codes_via_api_wholeblock_v1.xlsx\n",
      "Discarded rows saved to discharged_discarded_medications_v1.csv\n"
     ]
    }
   ],
   "source": [
    "#For the left out ones, which didn't had any match with the rxnorm downloaded list, therefore rxnorm API was used.\n",
    "#The output of the above code serves as the input for this code.\n",
    "\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Apply the nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'discharge_medications_with_rxnorm_codes_part1.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Filter out medications with names shorter than 3 characters and save the discarded rows\n",
    "discarded_data = data[data['medication_name'].str.len() < 3]\n",
    "data = data[data['medication_name'].str.len() >= 3]\n",
    "\n",
    "# Save discarded rows to a separate file\n",
    "discarded_output_path = 'discharged_discarded_medications.csv'\n",
    "discarded_data.to_csv(discarded_output_path, index=False)\n",
    "\n",
    "# Asynchronous function to validate medication name and get RxNorm code using RxNorm API\n",
    "rxnorm_cache = {}\n",
    "\n",
    "async def fetch_rxnorm_code(name, session):\n",
    "    if name in rxnorm_cache:\n",
    "        return name, rxnorm_cache[name]\n",
    "    \n",
    "    url = f\"https://rxnav.nlm.nih.gov/REST/rxcui.json?name={name}\"\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                if 'idGroup' in data and 'rxnormId' in data['idGroup']:\n",
    "                    rxnorm_code = data['idGroup']['rxnormId'][0]\n",
    "                    rxnorm_cache[name] = rxnorm_code\n",
    "                    return name, rxnorm_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {name}: {e}\")\n",
    "    \n",
    "    rxnorm_cache[name] = None\n",
    "    return name, None\n",
    "\n",
    "async def get_rxnorm_codes(medications):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_rxnorm_code(med, session) for med in medications]\n",
    "        return await tqdm_asyncio.gather(*tasks, desc=\"Fetching RxNorm codes\")\n",
    "\n",
    "# Extract unique medications to reduce API calls\n",
    "unique_medications = data['medication_name'].unique()\n",
    "\n",
    "# Fetch RxNorm codes for unique medications\n",
    "batch_size = 500 # Adjust batch size for optimal performance\n",
    "rxnorm_codes = []\n",
    "\n",
    "async def main():\n",
    "    for i in range(0, len(unique_medications), batch_size):\n",
    "        batch_medications = unique_medications[i:i + batch_size]\n",
    "        batch_rxnorm_codes = await get_rxnorm_codes(batch_medications)\n",
    "        rxnorm_codes.extend(batch_rxnorm_codes)\n",
    "\n",
    "# Run the async main function\n",
    "asyncio.run(main())\n",
    "\n",
    "# Convert to a dictionary for quick lookup\n",
    "rxnorm_codes_dict = {name: code for name, code in rxnorm_codes if code is not None}\n",
    "\n",
    "# Map RxNorm codes to the dataset\n",
    "data['rxnorm_code'] = data['medication_name'].map(rxnorm_codes_dict).fillna('')\n",
    "\n",
    "# Ensure all subject IDs are included, even if they have no medications\n",
    "all_subject_ids = data['subject_id'].unique()\n",
    "final_df = pd.merge(pd.DataFrame(all_subject_ids, columns=['subject_id']), data, on='subject_id', how='left')\n",
    "\n",
    "# Save the output to a new CSV file\n",
    "output_path = 'discharge_medications_with_rxnorm_codes_part2.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Output file saved to {output_path}\")\n",
    "print(f\"Discarded rows saved to {discarded_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved to Medications_on_discharge_filtered_subsets.xlsx\n"
     ]
    }
   ],
   "source": [
    "#The file generated from the second code above serves as the input for this code below\n",
    "#To filter the rows with subtext\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'discharge_medications_with_rxnorm_codes_part2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to filter out rows where medication name is a subtext of another medication name\n",
    "def filter_medications(group):\n",
    "    medication_names = group['medication_name'].tolist()\n",
    "    filtered_names = set(medication_names)  # Start with all names\n",
    "\n",
    "    for name in medication_names:\n",
    "        for other_name in medication_names:\n",
    "            if name != other_name and name in other_name:\n",
    "                filtered_names.discard(name)  # Remove name if it is a subtext of another name\n",
    "\n",
    "    return group[group['medication_name'].isin(filtered_names)]\n",
    "\n",
    "# Apply the filter function to each group of subject_id\n",
    "filtered_data = data.groupby('subject_id').apply(filter_medications).reset_index(drop=True)\n",
    "\n",
    "# Save the filtered dataset to a new CSV file\n",
    "output_file_path = 'medication_order_output_file.csv'\n",
    "filtered_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered dataset saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
